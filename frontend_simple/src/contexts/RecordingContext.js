import React, { createContext, useContext, useState, useRef, useEffect } from 'react';
import { analyzeAudio, saveAudioFile, getStorageSettings } from '../api';

const RecordingContext = createContext();

export const useRecording = () => {
  const context = useContext(RecordingContext);
  if (!context) {
    throw new Error('useRecording must be used within RecordingProvider');
  }
  return context;
};

export const RecordingProvider = ({ children }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [recordedAudioUrl, setRecordedAudioUrl] = useState(null);
  const [recordedFileName, setRecordedFileName] = useState(null);
  const [zones, setZones] = useState([
    { id: 1, name: 'Aë™ 1ì¸µ', area: 'í”„ë ˆìŠ¤ êµ¬ì—­', status: 'safe', lastDetection: null, predictions: null }
  ]);

  // Refë“¤ì„ ì „ì—­ìœ¼ë¡œ ê´€ë¦¬
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const microphoneRef = useRef(null);
  const monitoringIntervalRef = useRef(null);
  const streamRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const recordedChunksRef = useRef([]);

  // ë…¹ìŒ ì‹œê°„ ì—…ë°ì´íŠ¸
  useEffect(() => {
    let interval = null;
    if (isRecording) {
      interval = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
    } else {
      setRecordingTime(0);
    }
    return () => {
      if (interval) clearInterval(interval);
    };
  }, [isRecording]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopRecording();
      stopAudioMonitoring();
    };
  }, []);

  // ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
  const stopAudioMonitoring = () => {
    if (monitoringIntervalRef.current) {
      clearInterval(monitoringIntervalRef.current);
      monitoringIntervalRef.current = null;
    }
    if (microphoneRef.current) {
      microphoneRef.current.disconnect();
      microphoneRef.current = null;
    }
    if (analyserRef.current) {
      analyserRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(console.error);
      audioContextRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
  };

  // ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      // ë§ˆì´í¬ ì ‘ê·¼
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,
          sampleRate: 16000,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      streamRef.current = stream;

      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      audioContextRef.current = audioContext;

      // ì˜¤ë””ì˜¤ ë¶„ì„ ë…¸ë“œ ìƒì„±
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.8;
      analyserRef.current = analyser;

      const microphone = audioContext.createMediaStreamSource(stream);
      microphone.connect(analyser);
      microphoneRef.current = microphone;

      // MediaRecorderë¡œ ë…¹ìŒ ì‹œì‘
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      mediaRecorderRef.current = mediaRecorder;
      recordedChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        // ë…¹ìŒ ì™„ë£Œ ì‹œ íŒŒì¼ ìƒì„±
        const blob = new Blob(recordedChunksRef.current, { type: 'audio/webm' });
        const url = URL.createObjectURL(blob);
        setRecordedAudioUrl(url);
        
        // íŒŒì¼ëª… ìƒì„± (ë‚ ì§œ/ì‹œê°„ í¬í•¨)
        const now = new Date();
        const fileName = `recording_${now.getFullYear()}${String(now.getMonth() + 1).padStart(2, '0')}${String(now.getDate()).padStart(2, '0')}_${String(now.getHours()).padStart(2, '0')}${String(now.getMinutes()).padStart(2, '0')}${String(now.getSeconds()).padStart(2, '0')}.webm`;
        setRecordedFileName(fileName);
        
        // ìë™ ì €ì¥ í™•ì¸ ë° ì €ì¥
        try {
          console.log('ğŸ“¦ ìë™ ì €ì¥ í™•ì¸ ì¤‘...');
          const storageSettings = await getStorageSettings();
          console.log('ğŸ“¦ ì €ì¥ ì„¤ì •:', storageSettings);
          
          if (storageSettings && storageSettings.autoSaveEnabled) {
            console.log('âœ… ìë™ ì €ì¥ í™œì„±í™”ë¨, íŒŒì¼ ì €ì¥ ì‹œì‘...');
            // Blobì„ Base64ë¡œ ë³€í™˜
            const reader = new FileReader();
            reader.onloadend = async () => {
              try {
                const base64Data = reader.result.split(',')[1]; // data:audio/webm;base64, ë¶€ë¶„ ì œê±°
                console.log('ğŸ“¤ ì„œë²„ë¡œ íŒŒì¼ ì „ì†¡ ì¤‘...', fileName);
                const result = await saveAudioFile(base64Data, fileName);
                console.log('âœ… ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ ì €ì¥ ì™„ë£Œ:', fileName, result);
              } catch (error) {
                console.error('âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ ì €ì¥ ì‹¤íŒ¨:', error);
                console.error('ì—ëŸ¬ ìƒì„¸:', error.response?.data || error.message);
              }
            };
            reader.onerror = (error) => {
              console.error('âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨:', error);
            };
            reader.readAsDataURL(blob);
          } else {
            console.log('â„¹ï¸ ìë™ ì €ì¥ ë¹„í™œì„±í™”ë¨, ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í•„ìš”');
          }
        } catch (error) {
          console.error('âŒ ì €ì¥ ì„¤ì • í™•ì¸ ì‹¤íŒ¨:', error);
          console.error('ì—ëŸ¬ ìƒì„¸:', error.response?.data || error.message);
        }
      };

      // ë…¹ìŒ ì‹œì‘
      mediaRecorder.start(1000); // 1ì´ˆë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘
      setIsRecording(true);
      setRecordedAudioUrl(null);
      setRecordedFileName(null);

      // AI ë¶„ì„ ì‹œì‘ (3ì´ˆë§ˆë‹¤)
      startAudioAnalysis();

      console.log('âœ… ë…¹ìŒ ì‹œì‘');
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  // ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œì‘
  const startAudioAnalysis = () => {
    if (monitoringIntervalRef.current) {
      clearInterval(monitoringIntervalRef.current);
    }

    monitoringIntervalRef.current = setInterval(async () => {
      if (!analyserRef.current || !audioContextRef.current) return;

      try {
        // ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘ (ì‹œê°„ ë„ë©”ì¸ ë°ì´í„° ì‚¬ìš©)
        const bufferLength = analyserRef.current.fftSize;
        const timeData = new Float32Array(bufferLength);
        analyserRef.current.getFloatTimeDomainData(timeData);
        
        // Float32Arrayë¥¼ Listë¡œ ë³€í™˜
        const audioData = [];
        for (let i = 0; i < timeData.length; i++) {
          audioData.push(timeData[i]);
        }
        
        // ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì • (128 * 63 * 1 = 8064)
        const targetSize = 128 * 63 * 1;
        
        // ë°ì´í„° í¬ê¸° ì¡°ì •
        if (audioData.length > targetSize) {
          const step = audioData.length / targetSize;
          const resampled = [];
          for (let i = 0; i < targetSize; i++) {
            const index = Math.floor(i * step);
            resampled.push(audioData[index] || 0);
          }
          audioData.splice(0, audioData.length, ...resampled);
        } else {
          while (audioData.length < targetSize) {
            audioData.push(0.0);
          }
        }

        // AI ë¶„ì„ ìš”ì²­
        const result = await analyzeAudio(audioData, 16000, 1000);

        if (result.success) {
          // Aë™ 1ì¸µ ìƒíƒœ ì—…ë°ì´íŠ¸
          setZones(prevZones =>
            prevZones.map(zone => ({
              ...zone,
              status: result.isDangerous ? 'alert' : 'safe',
              lastDetection: result.isDangerous 
                ? new Date().toLocaleTimeString('ko-KR')
                : zone.lastDetection,
              predictions: result.predictions || null,
              predictedClass: result.predictedClass || 0,
            }))
          );
        }
      } catch (err) {
        console.error('ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨:', err);
      }
    }, 3000); // 3ì´ˆë§ˆë‹¤ ë¶„ì„
  };

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    try {
      // MediaRecorder ì¤‘ì§€
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        if (mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop();
        }
      }
      
      // ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
      stopAudioMonitoring();
      
      // ìƒíƒœ ì—…ë°ì´íŠ¸
      setIsRecording(false);
      
      console.log('â¹ï¸ ë…¹ìŒ ì¤‘ì§€');
    } catch (error) {
      console.error('ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨:', error);
      // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ìƒíƒœëŠ” ì—…ë°ì´íŠ¸
      stopAudioMonitoring();
      setIsRecording(false);
    }
  };

  // ë…¹ìŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
  const downloadRecording = () => {
    if (recordedAudioUrl && recordedFileName) {
      const a = document.createElement('a');
      a.href = recordedAudioUrl;
      a.download = recordedFileName;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
    }
  };

  const value = {
    isRecording,
    recordingTime,
    recordedAudioUrl,
    recordedFileName,
    zones,
    startRecording,
    stopRecording,
    downloadRecording,
  };

  return (
    <RecordingContext.Provider value={value}>
      {children}
    </RecordingContext.Provider>
  );
};

